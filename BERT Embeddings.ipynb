{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a758ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2377ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\Covid-19 Tweets\\covid19_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "170f71bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>·èâ·é•‚òª’¨ÍÇÖœÆ</td>\n",
       "      <td>astroworld</td>\n",
       "      <td>wednesday addams as a disney princess keepin i...</td>\n",
       "      <td>2017-05-26 05:46:42</td>\n",
       "      <td>624</td>\n",
       "      <td>950</td>\n",
       "      <td>18775</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-25 12:27:21</td>\n",
       "      <td>If I smelled the scent of hand sanitizers toda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom Basile üá∫üá∏</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Husband, Father, Columnist &amp; Commentator. Auth...</td>\n",
       "      <td>2009-04-16 20:06:23</td>\n",
       "      <td>2253</td>\n",
       "      <td>1677</td>\n",
       "      <td>24</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-07-25 12:27:17</td>\n",
       "      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Time4fisticuffs</td>\n",
       "      <td>Pewee Valley, KY</td>\n",
       "      <td>#Christian #Catholic #Conservative #Reagan #Re...</td>\n",
       "      <td>2009-02-28 18:57:41</td>\n",
       "      <td>9275</td>\n",
       "      <td>9525</td>\n",
       "      <td>7254</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-25 12:27:14</td>\n",
       "      <td>@diane3443 @wdunlap @realDonaldTrump Trump nev...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ethel mertz</td>\n",
       "      <td>Stuck in the Middle</td>\n",
       "      <td>#Browns #Indians #ClevelandProud #[]_[] #Cavs ...</td>\n",
       "      <td>2019-03-07 01:45:06</td>\n",
       "      <td>197</td>\n",
       "      <td>987</td>\n",
       "      <td>1488</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-25 12:27:10</td>\n",
       "      <td>@brookbanktv The one gift #COVID19 has give me...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DIPR-J&amp;K</td>\n",
       "      <td>Jammu and Kashmir</td>\n",
       "      <td>üñäÔ∏èOfficial Twitter handle of Department of Inf...</td>\n",
       "      <td>2017-02-12 06:45:15</td>\n",
       "      <td>101009</td>\n",
       "      <td>168</td>\n",
       "      <td>101</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-07-25 12:27:08</td>\n",
       "      <td>25 July : Media Bulletin on Novel #CoronaVirus...</td>\n",
       "      <td>['CoronaVirusUpdates', 'COVID19']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179103</th>\n",
       "      <td>AJIMATI AbdulRahman O.</td>\n",
       "      <td>Ilorin, Nigeria</td>\n",
       "      <td>Animal Scientist|| Muslim|| Real Madrid/Chelsea</td>\n",
       "      <td>2013-12-30 18:59:19</td>\n",
       "      <td>412</td>\n",
       "      <td>1609</td>\n",
       "      <td>1062</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-08-29 19:44:21</td>\n",
       "      <td>Thanks @IamOhmai for nominating me for the @WH...</td>\n",
       "      <td>['WearAMask']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179104</th>\n",
       "      <td>Jason</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>When your cat has more baking soda than Ninja ...</td>\n",
       "      <td>2011-12-21 04:41:30</td>\n",
       "      <td>150</td>\n",
       "      <td>182</td>\n",
       "      <td>7295</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-08-29 19:44:16</td>\n",
       "      <td>2020! The year of insanity! Lol! #COVID19 http...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179105</th>\n",
       "      <td>BEEHEMOTH ‚è≥</td>\n",
       "      <td>üá®üá¶ Canada</td>\n",
       "      <td>‚öíÔ∏è The Architects of Free Trade ‚öíÔ∏è Really Did ...</td>\n",
       "      <td>2016-07-13 17:21:59</td>\n",
       "      <td>1623</td>\n",
       "      <td>2160</td>\n",
       "      <td>98000</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-08-29 19:44:15</td>\n",
       "      <td>@CTVNews A powerful painting by Juan Lucena. I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179106</th>\n",
       "      <td>Gary DelPonte</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Global UX UI Visual Designer. StoryTeller, Mus...</td>\n",
       "      <td>2009-10-27 17:43:13</td>\n",
       "      <td>1338</td>\n",
       "      <td>1111</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-08-29 19:44:14</td>\n",
       "      <td>More than 1,200 students test positive for #CO...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179107</th>\n",
       "      <td>TUKY II</td>\n",
       "      <td>Aliwal North, South Africa</td>\n",
       "      <td>TOKELO SEKHOPA | TUKY II | LAST BORN | EISH TU...</td>\n",
       "      <td>2018-04-14 17:30:07</td>\n",
       "      <td>97</td>\n",
       "      <td>1697</td>\n",
       "      <td>566</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-08-29 19:44:08</td>\n",
       "      <td>I stop when I see a Stop\\n\\n@SABCNews\\n@Izinda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179108 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     user_name               user_location  \\\n",
       "0                       ·èâ·é•‚òª’¨ÍÇÖœÆ                  astroworld   \n",
       "1                Tom Basile üá∫üá∏                New York, NY   \n",
       "2              Time4fisticuffs            Pewee Valley, KY   \n",
       "3                  ethel mertz        Stuck in the Middle    \n",
       "4                     DIPR-J&K           Jammu and Kashmir   \n",
       "...                        ...                         ...   \n",
       "179103  AJIMATI AbdulRahman O.             Ilorin, Nigeria   \n",
       "179104                   Jason                     Ontario   \n",
       "179105             BEEHEMOTH ‚è≥                   üá®üá¶ Canada   \n",
       "179106           Gary DelPonte               New York City   \n",
       "179107                 TUKY II  Aliwal North, South Africa   \n",
       "\n",
       "                                         user_description  \\\n",
       "0       wednesday addams as a disney princess keepin i...   \n",
       "1       Husband, Father, Columnist & Commentator. Auth...   \n",
       "2       #Christian #Catholic #Conservative #Reagan #Re...   \n",
       "3       #Browns #Indians #ClevelandProud #[]_[] #Cavs ...   \n",
       "4       üñäÔ∏èOfficial Twitter handle of Department of Inf...   \n",
       "...                                                   ...   \n",
       "179103    Animal Scientist|| Muslim|| Real Madrid/Chelsea   \n",
       "179104  When your cat has more baking soda than Ninja ...   \n",
       "179105  ‚öíÔ∏è The Architects of Free Trade ‚öíÔ∏è Really Did ...   \n",
       "179106  Global UX UI Visual Designer. StoryTeller, Mus...   \n",
       "179107  TOKELO SEKHOPA | TUKY II | LAST BORN | EISH TU...   \n",
       "\n",
       "               user_created  user_followers  user_friends  user_favourites  \\\n",
       "0       2017-05-26 05:46:42             624           950            18775   \n",
       "1       2009-04-16 20:06:23            2253          1677               24   \n",
       "2       2009-02-28 18:57:41            9275          9525             7254   \n",
       "3       2019-03-07 01:45:06             197           987             1488   \n",
       "4       2017-02-12 06:45:15          101009           168              101   \n",
       "...                     ...             ...           ...              ...   \n",
       "179103  2013-12-30 18:59:19             412          1609             1062   \n",
       "179104  2011-12-21 04:41:30             150           182             7295   \n",
       "179105  2016-07-13 17:21:59            1623          2160            98000   \n",
       "179106  2009-10-27 17:43:13            1338          1111                0   \n",
       "179107  2018-04-14 17:30:07              97          1697              566   \n",
       "\n",
       "        user_verified                 date  \\\n",
       "0               False  2020-07-25 12:27:21   \n",
       "1                True  2020-07-25 12:27:17   \n",
       "2               False  2020-07-25 12:27:14   \n",
       "3               False  2020-07-25 12:27:10   \n",
       "4               False  2020-07-25 12:27:08   \n",
       "...               ...                  ...   \n",
       "179103          False  2020-08-29 19:44:21   \n",
       "179104          False  2020-08-29 19:44:16   \n",
       "179105          False  2020-08-29 19:44:15   \n",
       "179106          False  2020-08-29 19:44:14   \n",
       "179107          False  2020-08-29 19:44:08   \n",
       "\n",
       "                                                     text  \\\n",
       "0       If I smelled the scent of hand sanitizers toda...   \n",
       "1       Hey @Yankees @YankeesPR and @MLB - wouldn't it...   \n",
       "2       @diane3443 @wdunlap @realDonaldTrump Trump nev...   \n",
       "3       @brookbanktv The one gift #COVID19 has give me...   \n",
       "4       25 July : Media Bulletin on Novel #CoronaVirus...   \n",
       "...                                                   ...   \n",
       "179103  Thanks @IamOhmai for nominating me for the @WH...   \n",
       "179104  2020! The year of insanity! Lol! #COVID19 http...   \n",
       "179105  @CTVNews A powerful painting by Juan Lucena. I...   \n",
       "179106  More than 1,200 students test positive for #CO...   \n",
       "179107  I stop when I see a Stop\\n\\n@SABCNews\\n@Izinda...   \n",
       "\n",
       "                                 hashtags               source  is_retweet  \n",
       "0                                     NaN   Twitter for iPhone       False  \n",
       "1                                     NaN  Twitter for Android       False  \n",
       "2                             ['COVID19']  Twitter for Android       False  \n",
       "3                             ['COVID19']   Twitter for iPhone       False  \n",
       "4       ['CoronaVirusUpdates', 'COVID19']  Twitter for Android       False  \n",
       "...                                   ...                  ...         ...  \n",
       "179103                      ['WearAMask']  Twitter for Android       False  \n",
       "179104                        ['COVID19']  Twitter for Android       False  \n",
       "179105                                NaN      Twitter Web App       False  \n",
       "179106                        ['COVID19']   Twitter for iPhone       False  \n",
       "179107                                NaN  Twitter for Android       False  \n",
       "\n",
       "[179108 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29aaaf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 179108 entries, 0 to 179107\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   user_name         179108 non-null  object\n",
      " 1   user_location     142337 non-null  object\n",
      " 2   user_description  168822 non-null  object\n",
      " 3   user_created      179108 non-null  object\n",
      " 4   user_followers    179108 non-null  int64 \n",
      " 5   user_friends      179108 non-null  int64 \n",
      " 6   user_favourites   179108 non-null  int64 \n",
      " 7   user_verified     179108 non-null  bool  \n",
      " 8   date              179108 non-null  object\n",
      " 9   text              179108 non-null  object\n",
      " 10  hashtags          127774 non-null  object\n",
      " 11  source            179031 non-null  object\n",
      " 12  is_retweet        179108 non-null  bool  \n",
      "dtypes: bool(2), int64(3), object(8)\n",
      "memory usage: 15.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7b51b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_columns = ['text','hashtags','user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd3e6555",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(columns=df.columns.difference(important_columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e653937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pushp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef321a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer \n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16b51229",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d471057",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = r\"@\\w*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd0357c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import re\n",
    "\n",
    "def preprocess_text(sentence, stem=False):\n",
    "    sentence = re.sub(tags, \"\", sentence)\n",
    "    sentence = re.sub(r'http\\S+|www\\S+', '', sentence)\n",
    "    \n",
    "    if stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        processed_sentence = ' '.join(stemmer.stem(word.lower()) for word in sentence.split() if word.lower() not in stopwords)\n",
    "    else:\n",
    "        processed_sentence = ' '.join(word.lower() for word in sentence.split() if word.lower() not in stopwords)\n",
    "    \n",
    "    return processed_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1e69830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignal Text : Hey @Yankees @YankeesPR and @MLB - wouldn't it have made more sense to have the players pay their respects to the A‚Ä¶ https://t.co/1QvW0zgyPu\n",
      "\n",
      "Preprocessed Text : smelled scent hand sanitizers today someone past, would think intoxicated that‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "print(f\"Orignal Text : {df.text[1]}\")\n",
    "print()\n",
    "print(f\"Preprocessed Text : {preprocess_text(data.text[0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b30318b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['preprocessed'] = data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5276955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Sentence_no_punctuation\"] = data['preprocessed'].apply(lambda sentence: sentence.translate(str.maketrans('', '', string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11bac67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Sentence_tokens\"] = data[\"Sentence_no_punctuation\"].apply(nltk.word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5696c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>Sentence_no_punctuation</th>\n",
       "      <th>Sentence_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If I smelled the scent of hand sanitizers toda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>smelled scent hand sanitizers today someone pa...</td>\n",
       "      <td>smelled scent hand sanitizers today someone pa...</td>\n",
       "      <td>[smelled, scent, hand, sanitizers, today, some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hey - made sense players pay respects a‚Ä¶</td>\n",
       "      <td>hey  made sense players pay respects a‚Ä¶</td>\n",
       "      <td>[hey, made, sense, players, pay, respects, a‚Ä¶]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@diane3443 @wdunlap @realDonaldTrump Trump nev...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>trump never claimed #covid19 hoax. claim effor...</td>\n",
       "      <td>trump never claimed covid19 hoax claim effort to‚Ä¶</td>\n",
       "      <td>[trump, never, claimed, covid19, hoax, claim, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@brookbanktv The one gift #COVID19 has give me...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>one gift #covid19 give appreciation simple thi...</td>\n",
       "      <td>one gift covid19 give appreciation simple thin...</td>\n",
       "      <td>[one, gift, covid19, give, appreciation, simpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25 July : Media Bulletin on Novel #CoronaVirus...</td>\n",
       "      <td>['CoronaVirusUpdates', 'COVID19']</td>\n",
       "      <td>25 july : media bulletin novel #coronavirusupd...</td>\n",
       "      <td>25 july  media bulletin novel coronavirusupdat...</td>\n",
       "      <td>[25, july, media, bulletin, novel, coronavirus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179103</th>\n",
       "      <td>Thanks @IamOhmai for nominating me for the @WH...</td>\n",
       "      <td>['WearAMask']</td>\n",
       "      <td>thanks nominating #wearamask challenge. nomina...</td>\n",
       "      <td>thanks nominating wearamask challenge nominate ‚Ä¶</td>\n",
       "      <td>[thanks, nominating, wearamask, challenge, nom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179104</th>\n",
       "      <td>2020! The year of insanity! Lol! #COVID19 http...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>2020! year insanity! lol! #covid19</td>\n",
       "      <td>2020 year insanity lol covid19</td>\n",
       "      <td>[2020, year, insanity, lol, covid19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179105</th>\n",
       "      <td>@CTVNews A powerful painting by Juan Lucena. I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>powerful painting juan lucena. tribute grandpa...</td>\n",
       "      <td>powerful painting juan lucena tribute grandpar...</td>\n",
       "      <td>[powerful, painting, juan, lucena, tribute, gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179106</th>\n",
       "      <td>More than 1,200 students test positive for #CO...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>1,200 students test positive #covid19 major un...</td>\n",
       "      <td>1200 students test positive covid19 major univ...</td>\n",
       "      <td>[1200, students, test, positive, covid19, majo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179107</th>\n",
       "      <td>I stop when I see a Stop\\n\\n@SABCNews\\n@Izinda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stop see stop ‚Ä¶</td>\n",
       "      <td>stop see stop ‚Ä¶</td>\n",
       "      <td>[stop, see, stop, ‚Ä¶]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179108 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "0       If I smelled the scent of hand sanitizers toda...   \n",
       "1       Hey @Yankees @YankeesPR and @MLB - wouldn't it...   \n",
       "2       @diane3443 @wdunlap @realDonaldTrump Trump nev...   \n",
       "3       @brookbanktv The one gift #COVID19 has give me...   \n",
       "4       25 July : Media Bulletin on Novel #CoronaVirus...   \n",
       "...                                                   ...   \n",
       "179103  Thanks @IamOhmai for nominating me for the @WH...   \n",
       "179104  2020! The year of insanity! Lol! #COVID19 http...   \n",
       "179105  @CTVNews A powerful painting by Juan Lucena. I...   \n",
       "179106  More than 1,200 students test positive for #CO...   \n",
       "179107  I stop when I see a Stop\\n\\n@SABCNews\\n@Izinda...   \n",
       "\n",
       "                                 hashtags  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                             ['COVID19']   \n",
       "3                             ['COVID19']   \n",
       "4       ['CoronaVirusUpdates', 'COVID19']   \n",
       "...                                   ...   \n",
       "179103                      ['WearAMask']   \n",
       "179104                        ['COVID19']   \n",
       "179105                                NaN   \n",
       "179106                        ['COVID19']   \n",
       "179107                                NaN   \n",
       "\n",
       "                                             preprocessed  \\\n",
       "0       smelled scent hand sanitizers today someone pa...   \n",
       "1                hey - made sense players pay respects a‚Ä¶   \n",
       "2       trump never claimed #covid19 hoax. claim effor...   \n",
       "3       one gift #covid19 give appreciation simple thi...   \n",
       "4       25 july : media bulletin novel #coronavirusupd...   \n",
       "...                                                   ...   \n",
       "179103  thanks nominating #wearamask challenge. nomina...   \n",
       "179104                 2020! year insanity! lol! #covid19   \n",
       "179105  powerful painting juan lucena. tribute grandpa...   \n",
       "179106  1,200 students test positive #covid19 major un...   \n",
       "179107                                    stop see stop ‚Ä¶   \n",
       "\n",
       "                                  Sentence_no_punctuation  \\\n",
       "0       smelled scent hand sanitizers today someone pa...   \n",
       "1                 hey  made sense players pay respects a‚Ä¶   \n",
       "2       trump never claimed covid19 hoax claim effort to‚Ä¶   \n",
       "3       one gift covid19 give appreciation simple thin...   \n",
       "4       25 july  media bulletin novel coronavirusupdat...   \n",
       "...                                                   ...   \n",
       "179103   thanks nominating wearamask challenge nominate ‚Ä¶   \n",
       "179104                     2020 year insanity lol covid19   \n",
       "179105  powerful painting juan lucena tribute grandpar...   \n",
       "179106  1200 students test positive covid19 major univ...   \n",
       "179107                                    stop see stop ‚Ä¶   \n",
       "\n",
       "                                          Sentence_tokens  \n",
       "0       [smelled, scent, hand, sanitizers, today, some...  \n",
       "1          [hey, made, sense, players, pay, respects, a‚Ä¶]  \n",
       "2       [trump, never, claimed, covid19, hoax, claim, ...  \n",
       "3       [one, gift, covid19, give, appreciation, simpl...  \n",
       "4       [25, july, media, bulletin, novel, coronavirus...  \n",
       "...                                                   ...  \n",
       "179103  [thanks, nominating, wearamask, challenge, nom...  \n",
       "179104               [2020, year, insanity, lol, covid19]  \n",
       "179105  [powerful, painting, juan, lucena, tribute, gr...  \n",
       "179106  [1200, students, test, positive, covid19, majo...  \n",
       "179107                               [stop, see, stop, ‚Ä¶]  \n",
       "\n",
       "[179108 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "100c063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88f169ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68f96ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['input_ids'] = data['Sentence_tokens'].apply(lambda x: tokenizer.convert_tokens_to_ids(['[CLS]'] + x + ['[SEP]']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ea48fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>Sentence_no_punctuation</th>\n",
       "      <th>Sentence_tokens</th>\n",
       "      <th>input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If I smelled the scent of hand sanitizers toda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>smelled scent hand sanitizers today someone pa...</td>\n",
       "      <td>smelled scent hand sanitizers today someone pa...</td>\n",
       "      <td>[smelled, scent, hand, sanitizers, today, some...</td>\n",
       "      <td>[101, 9557, 6518, 2192, 100, 2651, 2619, 2627,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hey - made sense players pay respects a‚Ä¶</td>\n",
       "      <td>hey  made sense players pay respects a‚Ä¶</td>\n",
       "      <td>[hey, made, sense, players, pay, respects, a‚Ä¶]</td>\n",
       "      <td>[101, 4931, 2081, 3168, 2867, 3477, 17475, 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@diane3443 @wdunlap @realDonaldTrump Trump nev...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>trump never claimed #covid19 hoax. claim effor...</td>\n",
       "      <td>trump never claimed covid19 hoax claim effort to‚Ä¶</td>\n",
       "      <td>[trump, never, claimed, covid19, hoax, claim, ...</td>\n",
       "      <td>[101, 8398, 2196, 3555, 100, 28520, 4366, 3947...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@brookbanktv The one gift #COVID19 has give me...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>one gift #covid19 give appreciation simple thi...</td>\n",
       "      <td>one gift covid19 give appreciation simple thin...</td>\n",
       "      <td>[one, gift, covid19, give, appreciation, simpl...</td>\n",
       "      <td>[101, 2028, 5592, 100, 2507, 12284, 3722, 2477...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25 July : Media Bulletin on Novel #CoronaVirus...</td>\n",
       "      <td>['CoronaVirusUpdates', 'COVID19']</td>\n",
       "      <td>25 july : media bulletin novel #coronavirusupd...</td>\n",
       "      <td>25 july  media bulletin novel coronavirusupdat...</td>\n",
       "      <td>[25, july, media, bulletin, novel, coronavirus...</td>\n",
       "      <td>[101, 2423, 2251, 2865, 13146, 3117, 100, 100,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179103</th>\n",
       "      <td>Thanks @IamOhmai for nominating me for the @WH...</td>\n",
       "      <td>['WearAMask']</td>\n",
       "      <td>thanks nominating #wearamask challenge. nomina...</td>\n",
       "      <td>thanks nominating wearamask challenge nominate ‚Ä¶</td>\n",
       "      <td>[thanks, nominating, wearamask, challenge, nom...</td>\n",
       "      <td>[101, 4283, 100, 100, 4119, 23388, 1529, 102]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179104</th>\n",
       "      <td>2020! The year of insanity! Lol! #COVID19 http...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>2020! year insanity! lol! #covid19</td>\n",
       "      <td>2020 year insanity lol covid19</td>\n",
       "      <td>[2020, year, insanity, lol, covid19]</td>\n",
       "      <td>[101, 12609, 2095, 19272, 100, 100, 102]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179105</th>\n",
       "      <td>@CTVNews A powerful painting by Juan Lucena. I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>powerful painting juan lucena. tribute grandpa...</td>\n",
       "      <td>powerful painting juan lucena tribute grandpar...</td>\n",
       "      <td>[powerful, painting, juan, lucena, tribute, gr...</td>\n",
       "      <td>[101, 3928, 4169, 5348, 100, 7050, 14472, 2351...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179106</th>\n",
       "      <td>More than 1,200 students test positive for #CO...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>1,200 students test positive #covid19 major un...</td>\n",
       "      <td>1200 students test positive covid19 major univ...</td>\n",
       "      <td>[1200, students, test, positive, covid19, majo...</td>\n",
       "      <td>[101, 14840, 2493, 3231, 3893, 100, 2350, 2118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179107</th>\n",
       "      <td>I stop when I see a Stop\\n\\n@SABCNews\\n@Izinda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stop see stop ‚Ä¶</td>\n",
       "      <td>stop see stop ‚Ä¶</td>\n",
       "      <td>[stop, see, stop, ‚Ä¶]</td>\n",
       "      <td>[101, 2644, 2156, 2644, 1529, 102]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179108 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "0       If I smelled the scent of hand sanitizers toda...   \n",
       "1       Hey @Yankees @YankeesPR and @MLB - wouldn't it...   \n",
       "2       @diane3443 @wdunlap @realDonaldTrump Trump nev...   \n",
       "3       @brookbanktv The one gift #COVID19 has give me...   \n",
       "4       25 July : Media Bulletin on Novel #CoronaVirus...   \n",
       "...                                                   ...   \n",
       "179103  Thanks @IamOhmai for nominating me for the @WH...   \n",
       "179104  2020! The year of insanity! Lol! #COVID19 http...   \n",
       "179105  @CTVNews A powerful painting by Juan Lucena. I...   \n",
       "179106  More than 1,200 students test positive for #CO...   \n",
       "179107  I stop when I see a Stop\\n\\n@SABCNews\\n@Izinda...   \n",
       "\n",
       "                                 hashtags  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                             ['COVID19']   \n",
       "3                             ['COVID19']   \n",
       "4       ['CoronaVirusUpdates', 'COVID19']   \n",
       "...                                   ...   \n",
       "179103                      ['WearAMask']   \n",
       "179104                        ['COVID19']   \n",
       "179105                                NaN   \n",
       "179106                        ['COVID19']   \n",
       "179107                                NaN   \n",
       "\n",
       "                                             preprocessed  \\\n",
       "0       smelled scent hand sanitizers today someone pa...   \n",
       "1                hey - made sense players pay respects a‚Ä¶   \n",
       "2       trump never claimed #covid19 hoax. claim effor...   \n",
       "3       one gift #covid19 give appreciation simple thi...   \n",
       "4       25 july : media bulletin novel #coronavirusupd...   \n",
       "...                                                   ...   \n",
       "179103  thanks nominating #wearamask challenge. nomina...   \n",
       "179104                 2020! year insanity! lol! #covid19   \n",
       "179105  powerful painting juan lucena. tribute grandpa...   \n",
       "179106  1,200 students test positive #covid19 major un...   \n",
       "179107                                    stop see stop ‚Ä¶   \n",
       "\n",
       "                                  Sentence_no_punctuation  \\\n",
       "0       smelled scent hand sanitizers today someone pa...   \n",
       "1                 hey  made sense players pay respects a‚Ä¶   \n",
       "2       trump never claimed covid19 hoax claim effort to‚Ä¶   \n",
       "3       one gift covid19 give appreciation simple thin...   \n",
       "4       25 july  media bulletin novel coronavirusupdat...   \n",
       "...                                                   ...   \n",
       "179103   thanks nominating wearamask challenge nominate ‚Ä¶   \n",
       "179104                     2020 year insanity lol covid19   \n",
       "179105  powerful painting juan lucena tribute grandpar...   \n",
       "179106  1200 students test positive covid19 major univ...   \n",
       "179107                                    stop see stop ‚Ä¶   \n",
       "\n",
       "                                          Sentence_tokens  \\\n",
       "0       [smelled, scent, hand, sanitizers, today, some...   \n",
       "1          [hey, made, sense, players, pay, respects, a‚Ä¶]   \n",
       "2       [trump, never, claimed, covid19, hoax, claim, ...   \n",
       "3       [one, gift, covid19, give, appreciation, simpl...   \n",
       "4       [25, july, media, bulletin, novel, coronavirus...   \n",
       "...                                                   ...   \n",
       "179103  [thanks, nominating, wearamask, challenge, nom...   \n",
       "179104               [2020, year, insanity, lol, covid19]   \n",
       "179105  [powerful, painting, juan, lucena, tribute, gr...   \n",
       "179106  [1200, students, test, positive, covid19, majo...   \n",
       "179107                               [stop, see, stop, ‚Ä¶]   \n",
       "\n",
       "                                                input_ids  \n",
       "0       [101, 9557, 6518, 2192, 100, 2651, 2619, 2627,...  \n",
       "1       [101, 4931, 2081, 3168, 2867, 3477, 17475, 100...  \n",
       "2       [101, 8398, 2196, 3555, 100, 28520, 4366, 3947...  \n",
       "3       [101, 2028, 5592, 100, 2507, 12284, 3722, 2477...  \n",
       "4       [101, 2423, 2251, 2865, 13146, 3117, 100, 100,...  \n",
       "...                                                   ...  \n",
       "179103      [101, 4283, 100, 100, 4119, 23388, 1529, 102]  \n",
       "179104           [101, 12609, 2095, 19272, 100, 100, 102]  \n",
       "179105  [101, 3928, 4169, 5348, 100, 7050, 14472, 2351...  \n",
       "179106  [101, 14840, 2493, 3231, 3893, 100, 2350, 2118...  \n",
       "179107                 [101, 2644, 2156, 2644, 1529, 102]  \n",
       "\n",
       "[179108 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1044772",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8d598e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['input_ids'] = data['input_ids'].apply(lambda x: x + [0] * (max_length - len(x)))\n",
    "data['input_ids'] = data['input_ids'].apply(lambda x: x[:max_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e28d6352",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_tensor = torch.tensor(data['input_ids'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cc7a1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>preprocessed</th>\n",
       "      <th>Sentence_no_punctuation</th>\n",
       "      <th>Sentence_tokens</th>\n",
       "      <th>input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If I smelled the scent of hand sanitizers toda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>smelled scent hand sanitizers today someone pa...</td>\n",
       "      <td>smelled scent hand sanitizers today someone pa...</td>\n",
       "      <td>[smelled, scent, hand, sanitizers, today, some...</td>\n",
       "      <td>[101, 9557, 6518, 2192, 100, 2651, 2619, 2627,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hey - made sense players pay respects a‚Ä¶</td>\n",
       "      <td>hey  made sense players pay respects a‚Ä¶</td>\n",
       "      <td>[hey, made, sense, players, pay, respects, a‚Ä¶]</td>\n",
       "      <td>[101, 4931, 2081, 3168, 2867, 3477, 17475, 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@diane3443 @wdunlap @realDonaldTrump Trump nev...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>trump never claimed #covid19 hoax. claim effor...</td>\n",
       "      <td>trump never claimed covid19 hoax claim effort to‚Ä¶</td>\n",
       "      <td>[trump, never, claimed, covid19, hoax, claim, ...</td>\n",
       "      <td>[101, 8398, 2196, 3555, 100, 28520, 4366, 3947...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@brookbanktv The one gift #COVID19 has give me...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>one gift #covid19 give appreciation simple thi...</td>\n",
       "      <td>one gift covid19 give appreciation simple thin...</td>\n",
       "      <td>[one, gift, covid19, give, appreciation, simpl...</td>\n",
       "      <td>[101, 2028, 5592, 100, 2507, 12284, 3722, 2477...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25 July : Media Bulletin on Novel #CoronaVirus...</td>\n",
       "      <td>['CoronaVirusUpdates', 'COVID19']</td>\n",
       "      <td>25 july : media bulletin novel #coronavirusupd...</td>\n",
       "      <td>25 july  media bulletin novel coronavirusupdat...</td>\n",
       "      <td>[25, july, media, bulletin, novel, coronavirus...</td>\n",
       "      <td>[101, 2423, 2251, 2865, 13146, 3117, 100, 100,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179103</th>\n",
       "      <td>Thanks @IamOhmai for nominating me for the @WH...</td>\n",
       "      <td>['WearAMask']</td>\n",
       "      <td>thanks nominating #wearamask challenge. nomina...</td>\n",
       "      <td>thanks nominating wearamask challenge nominate ‚Ä¶</td>\n",
       "      <td>[thanks, nominating, wearamask, challenge, nom...</td>\n",
       "      <td>[101, 4283, 100, 100, 4119, 23388, 1529, 102, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179104</th>\n",
       "      <td>2020! The year of insanity! Lol! #COVID19 http...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>2020! year insanity! lol! #covid19</td>\n",
       "      <td>2020 year insanity lol covid19</td>\n",
       "      <td>[2020, year, insanity, lol, covid19]</td>\n",
       "      <td>[101, 12609, 2095, 19272, 100, 100, 102, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179105</th>\n",
       "      <td>@CTVNews A powerful painting by Juan Lucena. I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>powerful painting juan lucena. tribute grandpa...</td>\n",
       "      <td>powerful painting juan lucena tribute grandpar...</td>\n",
       "      <td>[powerful, painting, juan, lucena, tribute, gr...</td>\n",
       "      <td>[101, 3928, 4169, 5348, 100, 7050, 14472, 2351...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179106</th>\n",
       "      <td>More than 1,200 students test positive for #CO...</td>\n",
       "      <td>['COVID19']</td>\n",
       "      <td>1,200 students test positive #covid19 major un...</td>\n",
       "      <td>1200 students test positive covid19 major univ...</td>\n",
       "      <td>[1200, students, test, positive, covid19, majo...</td>\n",
       "      <td>[101, 14840, 2493, 3231, 3893, 100, 2350, 2118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179107</th>\n",
       "      <td>I stop when I see a Stop\\n\\n@SABCNews\\n@Izinda...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stop see stop ‚Ä¶</td>\n",
       "      <td>stop see stop ‚Ä¶</td>\n",
       "      <td>[stop, see, stop, ‚Ä¶]</td>\n",
       "      <td>[101, 2644, 2156, 2644, 1529, 102, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179108 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "0       If I smelled the scent of hand sanitizers toda...   \n",
       "1       Hey @Yankees @YankeesPR and @MLB - wouldn't it...   \n",
       "2       @diane3443 @wdunlap @realDonaldTrump Trump nev...   \n",
       "3       @brookbanktv The one gift #COVID19 has give me...   \n",
       "4       25 July : Media Bulletin on Novel #CoronaVirus...   \n",
       "...                                                   ...   \n",
       "179103  Thanks @IamOhmai for nominating me for the @WH...   \n",
       "179104  2020! The year of insanity! Lol! #COVID19 http...   \n",
       "179105  @CTVNews A powerful painting by Juan Lucena. I...   \n",
       "179106  More than 1,200 students test positive for #CO...   \n",
       "179107  I stop when I see a Stop\\n\\n@SABCNews\\n@Izinda...   \n",
       "\n",
       "                                 hashtags  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                             ['COVID19']   \n",
       "3                             ['COVID19']   \n",
       "4       ['CoronaVirusUpdates', 'COVID19']   \n",
       "...                                   ...   \n",
       "179103                      ['WearAMask']   \n",
       "179104                        ['COVID19']   \n",
       "179105                                NaN   \n",
       "179106                        ['COVID19']   \n",
       "179107                                NaN   \n",
       "\n",
       "                                             preprocessed  \\\n",
       "0       smelled scent hand sanitizers today someone pa...   \n",
       "1                hey - made sense players pay respects a‚Ä¶   \n",
       "2       trump never claimed #covid19 hoax. claim effor...   \n",
       "3       one gift #covid19 give appreciation simple thi...   \n",
       "4       25 july : media bulletin novel #coronavirusupd...   \n",
       "...                                                   ...   \n",
       "179103  thanks nominating #wearamask challenge. nomina...   \n",
       "179104                 2020! year insanity! lol! #covid19   \n",
       "179105  powerful painting juan lucena. tribute grandpa...   \n",
       "179106  1,200 students test positive #covid19 major un...   \n",
       "179107                                    stop see stop ‚Ä¶   \n",
       "\n",
       "                                  Sentence_no_punctuation  \\\n",
       "0       smelled scent hand sanitizers today someone pa...   \n",
       "1                 hey  made sense players pay respects a‚Ä¶   \n",
       "2       trump never claimed covid19 hoax claim effort to‚Ä¶   \n",
       "3       one gift covid19 give appreciation simple thin...   \n",
       "4       25 july  media bulletin novel coronavirusupdat...   \n",
       "...                                                   ...   \n",
       "179103   thanks nominating wearamask challenge nominate ‚Ä¶   \n",
       "179104                     2020 year insanity lol covid19   \n",
       "179105  powerful painting juan lucena tribute grandpar...   \n",
       "179106  1200 students test positive covid19 major univ...   \n",
       "179107                                    stop see stop ‚Ä¶   \n",
       "\n",
       "                                          Sentence_tokens  \\\n",
       "0       [smelled, scent, hand, sanitizers, today, some...   \n",
       "1          [hey, made, sense, players, pay, respects, a‚Ä¶]   \n",
       "2       [trump, never, claimed, covid19, hoax, claim, ...   \n",
       "3       [one, gift, covid19, give, appreciation, simpl...   \n",
       "4       [25, july, media, bulletin, novel, coronavirus...   \n",
       "...                                                   ...   \n",
       "179103  [thanks, nominating, wearamask, challenge, nom...   \n",
       "179104               [2020, year, insanity, lol, covid19]   \n",
       "179105  [powerful, painting, juan, lucena, tribute, gr...   \n",
       "179106  [1200, students, test, positive, covid19, majo...   \n",
       "179107                               [stop, see, stop, ‚Ä¶]   \n",
       "\n",
       "                                                input_ids  \n",
       "0       [101, 9557, 6518, 2192, 100, 2651, 2619, 2627,...  \n",
       "1       [101, 4931, 2081, 3168, 2867, 3477, 17475, 100...  \n",
       "2       [101, 8398, 2196, 3555, 100, 28520, 4366, 3947...  \n",
       "3       [101, 2028, 5592, 100, 2507, 12284, 3722, 2477...  \n",
       "4       [101, 2423, 2251, 2865, 13146, 3117, 100, 100,...  \n",
       "...                                                   ...  \n",
       "179103  [101, 4283, 100, 100, 4119, 23388, 1529, 102, ...  \n",
       "179104  [101, 12609, 2095, 19272, 100, 100, 102, 0, 0,...  \n",
       "179105  [101, 3928, 4169, 5348, 100, 7050, 14472, 2351...  \n",
       "179106  [101, 14840, 2493, 3231, 3893, 100, 2350, 2118...  \n",
       "179107  [101, 2644, 2156, 2644, 1529, 102, 0, 0, 0, 0,...  \n",
       "\n",
       "[179108 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a91d8588",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500  # Adjust the batch size to a smaller value\n",
    "\n",
    "# Generate the BERT embeddings in batches\n",
    "with torch.no_grad():\n",
    "    embeddings = []\n",
    "    for i in range(0, 5000, batch_size):\n",
    "        input_ids_batch = input_ids_tensor[i:i+batch_size]\n",
    "        outputs = model(input_ids_batch)\n",
    "        embeddings_batch = outputs[0][:, 0, :].tolist()\n",
    "        embeddings.extend(embeddings_batch)\n",
    "\n",
    "# Store the embeddings in a list\n",
    "sentence_embeddings1 = embeddings[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64228b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d25365c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c799e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8641b27f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cbd2e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46afc5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8d4468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c7d992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e69eaf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e0a2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de3c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d26cdfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca00555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
